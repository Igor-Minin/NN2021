{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lr4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMEkpGJfmhDQ8ADveaIe0lH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Igor-Minin/NN2021/blob/master/lr4/lr4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6eEXCFvAO0Li",
        "outputId": "074fa3cc-fbd0-45de-a5ba-c73ed4da39e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.1671 - accuracy: 0.1606 - val_loss: 1.7959 - val_accuracy: 0.2046\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.7066 - accuracy: 0.2509 - val_loss: 1.6567 - val_accuracy: 0.2805\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.6321 - accuracy: 0.2806 - val_loss: 1.6094 - val_accuracy: 0.2857\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.6052 - accuracy: 0.2833 - val_loss: 1.6041 - val_accuracy: 0.2859\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5975 - accuracy: 0.2862 - val_loss: 1.6064 - val_accuracy: 0.2756\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5950 - accuracy: 0.2920 - val_loss: 1.5747 - val_accuracy: 0.2994\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5775 - accuracy: 0.3040 - val_loss: 1.6030 - val_accuracy: 0.3000\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5708 - accuracy: 0.3175 - val_loss: 1.5635 - val_accuracy: 0.3315\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5638 - accuracy: 0.3280 - val_loss: 1.5534 - val_accuracy: 0.3334\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5432 - accuracy: 0.3346 - val_loss: 1.5390 - val_accuracy: 0.3549\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.0966 - accuracy: 0.6275 - val_loss: 0.7959 - val_accuracy: 0.7328\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7063 - accuracy: 0.7535 - val_loss: 0.6690 - val_accuracy: 0.7627\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6184 - accuracy: 0.7861 - val_loss: 0.6178 - val_accuracy: 0.7841\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5817 - accuracy: 0.7986 - val_loss: 0.5948 - val_accuracy: 0.7950\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5615 - accuracy: 0.8047 - val_loss: 0.5959 - val_accuracy: 0.7876\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5451 - accuracy: 0.8095 - val_loss: 0.5637 - val_accuracy: 0.8024\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5350 - accuracy: 0.8119 - val_loss: 0.5496 - val_accuracy: 0.8093\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5249 - accuracy: 0.8167 - val_loss: 0.5610 - val_accuracy: 0.8046\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5171 - accuracy: 0.8182 - val_loss: 0.5378 - val_accuracy: 0.8110\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5100 - accuracy: 0.8208 - val_loss: 0.5439 - val_accuracy: 0.8050\n",
            "Epoch 1/40\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.2800 - accuracy: 0.5474 - val_loss: 0.8367 - val_accuracy: 0.6707 - lr: 0.0010\n",
            "Epoch 2/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7327 - accuracy: 0.7145 - val_loss: 0.6879 - val_accuracy: 0.7373 - lr: 0.0011\n",
            "Epoch 3/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6494 - accuracy: 0.7531 - val_loss: 0.6542 - val_accuracy: 0.7552 - lr: 0.0013\n",
            "Epoch 4/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6131 - accuracy: 0.7721 - val_loss: 0.6389 - val_accuracy: 0.7622 - lr: 0.0014\n",
            "Epoch 5/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5896 - accuracy: 0.7804 - val_loss: 0.6342 - val_accuracy: 0.7664 - lr: 0.0016\n",
            "Epoch 6/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5731 - accuracy: 0.7880 - val_loss: 0.6229 - val_accuracy: 0.7781 - lr: 0.0018\n",
            "Epoch 7/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5600 - accuracy: 0.7956 - val_loss: 0.5910 - val_accuracy: 0.7911 - lr: 0.0020\n",
            "Epoch 8/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5497 - accuracy: 0.8028 - val_loss: 0.5640 - val_accuracy: 0.7990 - lr: 0.0022\n",
            "Epoch 9/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5387 - accuracy: 0.8073 - val_loss: 0.5676 - val_accuracy: 0.7995 - lr: 0.0025\n",
            "Epoch 10/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5342 - accuracy: 0.8121 - val_loss: 0.5706 - val_accuracy: 0.8027 - lr: 0.0028\n",
            "Epoch 11/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5302 - accuracy: 0.8134 - val_loss: 0.5756 - val_accuracy: 0.7971 - lr: 0.0032\n",
            "Epoch 12/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5296 - accuracy: 0.8119 - val_loss: 0.5535 - val_accuracy: 0.8016 - lr: 0.0035\n",
            "Epoch 13/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5278 - accuracy: 0.8128 - val_loss: 0.5954 - val_accuracy: 0.7976 - lr: 0.0040\n",
            "Epoch 14/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5248 - accuracy: 0.8162 - val_loss: 0.5487 - val_accuracy: 0.8063 - lr: 0.0045\n",
            "Epoch 15/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5270 - accuracy: 0.8151 - val_loss: 0.5533 - val_accuracy: 0.8086 - lr: 0.0050\n",
            "Epoch 16/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5285 - accuracy: 0.8136 - val_loss: 0.5515 - val_accuracy: 0.8023 - lr: 0.0056\n",
            "Epoch 17/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5263 - accuracy: 0.8152 - val_loss: 0.5731 - val_accuracy: 0.8036 - lr: 0.0063\n",
            "Epoch 18/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5273 - accuracy: 0.8148 - val_loss: 0.5426 - val_accuracy: 0.8135 - lr: 0.0071\n",
            "Epoch 19/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5303 - accuracy: 0.8137 - val_loss: 0.5840 - val_accuracy: 0.7989 - lr: 0.0079\n",
            "Epoch 20/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5387 - accuracy: 0.8127 - val_loss: 0.5504 - val_accuracy: 0.8095 - lr: 0.0089\n",
            "Epoch 21/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5405 - accuracy: 0.8133 - val_loss: 0.6495 - val_accuracy: 0.7706 - lr: 0.0100\n",
            "Epoch 22/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5438 - accuracy: 0.8085 - val_loss: 0.5874 - val_accuracy: 0.7960 - lr: 0.0112\n",
            "Epoch 23/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5559 - accuracy: 0.8080 - val_loss: 0.6274 - val_accuracy: 0.7818 - lr: 0.0126\n",
            "Epoch 24/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5602 - accuracy: 0.8057 - val_loss: 0.5677 - val_accuracy: 0.8023 - lr: 0.0141\n",
            "Epoch 25/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5655 - accuracy: 0.8037 - val_loss: 0.6497 - val_accuracy: 0.7880 - lr: 0.0158\n",
            "Epoch 26/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5859 - accuracy: 0.7995 - val_loss: 0.8079 - val_accuracy: 0.7164 - lr: 0.0178\n",
            "Epoch 27/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5950 - accuracy: 0.7948 - val_loss: 0.6809 - val_accuracy: 0.7729 - lr: 0.0200\n",
            "Epoch 28/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6115 - accuracy: 0.7915 - val_loss: 0.6260 - val_accuracy: 0.7969 - lr: 0.0224\n",
            "Epoch 29/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6221 - accuracy: 0.7889 - val_loss: 0.6180 - val_accuracy: 0.7893 - lr: 0.0251\n",
            "Epoch 30/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6421 - accuracy: 0.7833 - val_loss: 0.6797 - val_accuracy: 0.7766 - lr: 0.0282\n",
            "Epoch 31/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6549 - accuracy: 0.7845 - val_loss: 0.6591 - val_accuracy: 0.7712 - lr: 0.0316\n",
            "Epoch 32/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6923 - accuracy: 0.7714 - val_loss: 0.6684 - val_accuracy: 0.7838 - lr: 0.0355\n",
            "Epoch 33/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7301 - accuracy: 0.7556 - val_loss: 0.8234 - val_accuracy: 0.7307 - lr: 0.0398\n",
            "Epoch 34/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7777 - accuracy: 0.7149 - val_loss: 0.9067 - val_accuracy: 0.7129 - lr: 0.0447\n",
            "Epoch 35/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.8409 - accuracy: 0.6935 - val_loss: 0.8685 - val_accuracy: 0.6826 - lr: 0.0501\n",
            "Epoch 36/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.9148 - accuracy: 0.6698 - val_loss: 0.9048 - val_accuracy: 0.6363 - lr: 0.0562\n",
            "Epoch 37/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.9923 - accuracy: 0.5902 - val_loss: 1.0671 - val_accuracy: 0.5934 - lr: 0.0631\n",
            "Epoch 38/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.2698 - accuracy: 0.4678 - val_loss: 1.3314 - val_accuracy: 0.4236 - lr: 0.0708\n",
            "Epoch 39/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5894 - accuracy: 0.3300 - val_loss: 1.5581 - val_accuracy: 0.2964 - lr: 0.0794\n",
            "Epoch 40/40\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.8078 - accuracy: 0.2638 - val_loss: 2.0674 - val_accuracy: 0.1672 - lr: 0.0891\n",
            "39\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "class1_data, class1_label = train_data[7], train_labels[7]\n",
        "class2_data, class2_label = train_data[0], train_labels[0]\n",
        "class3_data, class3_label = train_data[4], train_labels[4]\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "plt.imshow(class1_data, cmap=plt.cm.binary)\n",
        "plt.title(class_names[class1_label]);\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model1.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])\n",
        "non_norm_fitted_model = model1.fit(train_data, train_labels, epochs=10, validation_data=(test_data, test_labels))\n",
        "\n",
        "train_data = train_data / 255.0\n",
        "test_data = test_data / 255.0\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer (we had to reshape 28x28 to 784)\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"softmax\") # output shape is 10, activation is softmax\n",
        "])\n",
        "model2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "norm_fitted_model = model2.fit(train_data,\n",
        "                            train_labels,\n",
        "                            epochs=10,\n",
        "                            validation_data=(test_data, test_labels))\n",
        "model3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer (we had to reshape 28x28 to 784)\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"softmax\") # output shape is 10, activation is softmax\n",
        "])\n",
        "\n",
        "model3.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-3 * 10**(epoch/20))\n",
        "\n",
        "find_lr = model3.fit(train_data,\n",
        "                               train_labels,\n",
        "                               epochs=40, \n",
        "                               validation_data=(test_data, test_labels),\n",
        "                               callbacks=[lr_scheduler])\n"
      ]
    }
  ]
}